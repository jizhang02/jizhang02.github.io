---
layout:     post
title:      "Explainable Artificial Intelligence."
subtitle: "可解释的人工智能"
date:       2021-05-06 11:22:00
author:     "Jing"
header-img: "img/post-bg.jpg"
tags:
    - Computer Science
    - Deep Learning
    - XAI
---

### Let you know the principle of AI models from excellent works
This post is the collection of explainable AI techniques, tools, applications and reviews.
### ✅ Techniques
◾ [Class Activation maps](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Zhou_Learning_Deep_Features_CVPR_2016_paper.html)        
◾ [Anchors](https://ojs.aaai.org/index.php/AAAI/article/view/11491)    
◾ [Contextual Prediction Difference Analysis](https://arxiv.org/abs/1910.09086)    
◾ [Shapley Value Sampling](https://doi.org/10.1016/j.cor.2008.04.004)    
◾ [DeConvNet](https://doi.org/10.1007/978-3-319-10590-1_53)    
◾ [Excitation Backprop](https://doi.org/10.1007/s11263-017-1059-x)    
◾ [ExtremalPerturbation](https://openaccess.thecvf.com/content_ICCV_2019/html/Fong_Understanding_Deep_Networks_via_Extremal_Perturbations_and_Smooth_Masks_ICCV_2019_paper.html)    
◾ [Gradient/Saliency Maps](https://arxiv.org/abs/1312.6034)    
◾ [Guided backpropagation](https://arxiv.org/abs/1412.6806)    
◾ [NeuronGuidedBackprop](https://arxiv.org/abs/1412.6806)    
◾ [GNNExplainer](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7138248/)    
◾ [GNN-LRP](https://arxiv.org/abs/2006.03589)    
◾ [Layer-wise Relevance Propagation](https://doi.org/10.1371/journal.pone.0130140)    
◾ [LayerConductance](https://arxiv.org/abs/1807.09946)    
◾ [Local Rule-based Explanations](https://arxiv.org/abs/1805.10820)    
◾ [LIME](https://doi.org/10.1145/2939672.2939778) 📝[Introduction](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)    
◾ [RISE](https://arxiv.org/abs/1806.07421)    
◾ [Gradient * input](https://arxiv.org/abs/1605.01713)    
◾ [Gradient SHAP](https://arxiv.org/abs/1705.07874)    
◾ [FullGrad](https://arxiv.org/abs/1705.07874)    
◾ [GradCAM](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html)    
◾ [Guided GradCAM](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html)    
◾ [Integrated Gradients](http://proceedings.mlr.press/v70/sundararajan17a.html)   
◾ [Internal Influence](10.1109/TEST.2018.8624792)    
◾ [Expressive gradients](https://doi.org/10.1371/journal.pone.0215076)    
◾ [DeepTaylor](https://doi.org/10.1016/j.patcog.2016.11.008)    
◾ [PatternNet](https://arxiv.org/abs/1705.05598)    
◾ [Pattern Attribution](https://arxiv.org/abs/1705.05598)    
◾ [Prediction Difference Analysis](https://arxiv.org/abs/1702.04595)    
◾ [DeepLIFT](http://proceedings.mlr.press/v70/shrikumar17a)    
◾ [DeepLIFT SHAP](https://arxiv.org/abs/1705.07874)    
◾ [Kernel SHAP](https://arxiv.org/abs/1705.07874)    
◾ [SmoothGrad](https://arxiv.org/abs/1706.03825)    
◾ [Deep SHAP](https://doi.org/10.1007/978-3-030-53352-6_24)   
◾ [SHAP Interaction Index](https://doi.org/10.1038/s42256-019-0138-9)    
◾ [Occlusion](https://doi.org/10.1007/978-3-319-10590-1_53)    
◾ [Meaningful Perturbation](https://openaccess.thecvf.com/content_iccv_2017/html/Fong_Interpretable_Explanations_of_ICCV_2017_paper.html)    
◾ [NeuronConductance](https://arxiv.org/abs/1805.12233)    
◾ [TotalConductance](https://arxiv.org/abs/1805.12233)    
◾ [DeepDreams](https://doi.org/10.1007/978-3-030-33850-3_7)    
◾ [Spectral Relevance Analysis](https://doi.org/10.1038/s41467-019-08987-4)    
◾ [Tree Explainer](https://doi.org/10.1038/s42256-019-0138-9)    
◾ [TCAV](http://proceedings.mlr.press/v80/kim18d.html)    
◾ [TCAV with RCV](https://doi.org/10.1007/978-3-030-02628-8_14)    
◾ [UBS](https://doi.org/10.1007/978-3-030-33850-3_2)    
◾ [VarGrad](https://arxiv.org/abs/1810.03307)    
◾ [SENN](https://arxiv.org/abs/1810.03307)    




### ✅ Tools & Applications
🔸  [Heatmapping](http://www.heatmapping.org/)[web]    
🔸  [CNN-explainer](https://poloclub.github.io/cnn-explainer/)[web]    
🔸  [Explainable AI Demos](https://lrpserver.hhi.fraunhofer.de/)[web]    
🔸  [A Neural Network Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=7,2,2,2&seed=0.40403&showTestData=false&discretize=false&percTrainData=50&x=true&y=false&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)[web]    
🔸  [Summit](https://fredhohman.com/summit/)[web]    
🔸  [NeuralDivergence](http://haekyu.com/neural-divergence/)[web]    
🔸  [SCIN](https://www.dfki.de/skincare/classify.html)[web]    
🔸  [Neuroscope](https://github.com/c3di/neuroscope)[software]   
🔸  [LUCID](https://github.com/tensorflow/lucid)[library]    
🔸  [Keras-vis](https://raghakot.github.io/keras-vis/)[library]    
🔸  [DeepExplain](https://github.com/marcoancona/DeepExplain)[library]    
🔸  [iNNvestigate](https://github.com/albermax/innvestigate)[library]  
🔸  [TensorFlow Graph Visualizer](https://www.tensorflow.org/tensorboard/graphs)[library]    
🔸  [tf-explain](https://tf-explain.readthedocs.io/en/latest/)[library]    
🔸  [TorchRay](https://github.com/facebookresearch/TorchRay)[library]    
🔸  [Captum](https://captum.ai/)[library]    
🔸  [Explainable AI](https://cloud.google.com/explainable-ai)[commercial]    
🔸  [Explainable AI Platform](https://datalanguage.com/scopa-scalable-explainable-ai)[commercial]    
🔸  [exAID](https://exaid.kl.dfki.de/)[commercial]    
🔸  [DASL](https://www.decodedhealth.com/)[commercial]

### ✅ Reviews

🔹  [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/) A Guide for Making Black Box Models Explainable.
Christoph Molnar    
🔹  [Towards Robust Interpretability with Self-Explaining Neural Networks](https://arxiv.org/abs/1806.07538), 2018    
🔹  [Towards Explainable Artificial Intelligence](https://doi.org/10.1007/978-3-030-28954-6_1), 2019    
🔹  [On the Integration of Knowledge Graphs into Deep Learning Models for a More Comprehensible AI—Three Challenges for Future Research](https://doi.org/10.3390/info11020122), 2020    
🔹  [Explainable Deep Learning: A Field Guide for the Uninitiated](https://arxiv.org/abs/2004.14545), 2020    
🔹  [A Survey on Explainable Artificial Intelligence (XAI): Towards Medical XAI](https://arxiv.org/abs/1907.07374), 2020    
🔹  [Explainable Artificial Intelligence (xAI) Approaches and Deep Meta-Learning Models](10.5772/intechopen.92172), 2020    
🔹  [Explainable Deep Learning Models in Medical Image Analysis](https://doi.org/10.3390/jimaging6060052), 2020    
🔹  [Achievements and Challenges in Explaining Deep Learning based Computer-Aided Diagnosis Systems](https://arxiv.org/abs/2011.13169), 2020    
🔹  [Interpretability and Explainability: A Machine Learning Zoo Mini-tour](https://arxiv.org/abs/2012.01805), 2020    
🔹  [Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications](10.1109/JPROC.2021.3060483), 2021    


### ✅ Evaluations
◽ [The (Un)reliability of Saliency Methods: input variant](https://doi.org/10.1007/978-3-030-28954-6_14)    
◽ [Sanity Checks for Saliency Maps: model and data](https://arxiv.org/abs/1810.03292)      
◽ [Evaluating the Visualization of What a Deep Neural Network Has Learned: AOPC](https://ieeexplore.ieee.org/abstract/document/7552539)      



