---
layout:     post
title:      "Explainable Artificial Intelligence."
subtitle: "å¯è§£é‡Šçš„äººå·¥æ™ºèƒ½"
date:       2021-05-06 11:22:00
author:     "Jing"
header-img: "img/post-bg.jpg"
tags:
    - Computer Science
    - Deep Learning
    - XAI
---

### Let you know the principle of AI models from excellent works
This post is the collection of explainable AI techniques, tools, applications and reviews.
### âœ… Techniques
â—¾ [Class Activation maps](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Zhou_Learning_Deep_Features_CVPR_2016_paper.html)        
â—¾ [Anchors](https://ojs.aaai.org/index.php/AAAI/article/view/11491)    
â—¾ [Contextual Prediction Difference Analysis](https://arxiv.org/abs/1910.09086)    
â—¾ [Shapley Value Sampling](https://doi.org/10.1016/j.cor.2008.04.004)    
â—¾ [DeConvNet](https://doi.org/10.1007/978-3-319-10590-1_53)    
â—¾ [Excitation Backprop](https://doi.org/10.1007/s11263-017-1059-x)    
â—¾ [ExtremalPerturbation](https://openaccess.thecvf.com/content_ICCV_2019/html/Fong_Understanding_Deep_Networks_via_Extremal_Perturbations_and_Smooth_Masks_ICCV_2019_paper.html)    
â—¾ [Gradient/Saliency Maps](https://arxiv.org/abs/1312.6034)    
â—¾ [Guided backpropagation](https://arxiv.org/abs/1412.6806)    
â—¾ [NeuronGuidedBackprop](https://arxiv.org/abs/1412.6806)    
â—¾ [GNNExplainer](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7138248/)    
â—¾ [GNN-LRP](https://arxiv.org/abs/2006.03589)    
â—¾ [Layer-wise Relevance Propagation](https://doi.org/10.1371/journal.pone.0130140)    
â—¾ [LayerConductance](https://arxiv.org/abs/1807.09946)    
â—¾ [Local Rule-based Explanations](https://arxiv.org/abs/1805.10820)    
â—¾ [LIME](https://doi.org/10.1145/2939672.2939778) ğŸ“[Introduction](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)    
â—¾ [RISE](https://arxiv.org/abs/1806.07421)    
â—¾ [Gradient * input](https://arxiv.org/abs/1605.01713)    
â—¾ [Gradient SHAP](https://arxiv.org/abs/1705.07874)    
â—¾ [FullGrad](https://arxiv.org/abs/1705.07874)    
â—¾ [GradCAM](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html)    
â—¾ [Guided GradCAM](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html)    
â—¾ [Integrated Gradients](http://proceedings.mlr.press/v70/sundararajan17a.html)   
â—¾ [Internal Influence](10.1109/TEST.2018.8624792)    
â—¾ [Expressive gradients](https://doi.org/10.1371/journal.pone.0215076)    
â—¾ [DeepTaylor](https://doi.org/10.1016/j.patcog.2016.11.008)    
â—¾ [PatternNet](https://arxiv.org/abs/1705.05598)    
â—¾ [Pattern Attribution](https://arxiv.org/abs/1705.05598)    
â—¾ [Prediction Difference Analysis](https://arxiv.org/abs/1702.04595)    
â—¾ [DeepLIFT](http://proceedings.mlr.press/v70/shrikumar17a)    
â—¾ [DeepLIFT SHAP](https://arxiv.org/abs/1705.07874)    
â—¾ [Kernel SHAP](https://arxiv.org/abs/1705.07874)    
â—¾ [SmoothGrad](https://arxiv.org/abs/1706.03825)    
â—¾ [Deep SHAP](https://doi.org/10.1007/978-3-030-53352-6_24)   
â—¾ [SHAP Interaction Index](https://doi.org/10.1038/s42256-019-0138-9)    
â—¾ [Occlusion](https://doi.org/10.1007/978-3-319-10590-1_53)    
â—¾ [Meaningful Perturbation](https://openaccess.thecvf.com/content_iccv_2017/html/Fong_Interpretable_Explanations_of_ICCV_2017_paper.html)    
â—¾ [NeuronConductance](https://arxiv.org/abs/1805.12233)    
â—¾ [TotalConductance](https://arxiv.org/abs/1805.12233)    
â—¾ [DeepDreams](https://doi.org/10.1007/978-3-030-33850-3_7)    
â—¾ [Spectral Relevance Analysis](https://doi.org/10.1038/s41467-019-08987-4)    
â—¾ [Tree Explainer](https://doi.org/10.1038/s42256-019-0138-9)    
â—¾ [TCAV](http://proceedings.mlr.press/v80/kim18d.html)    
â—¾ [TCAV with RCV](https://doi.org/10.1007/978-3-030-02628-8_14)    
â—¾ [UBS](https://doi.org/10.1007/978-3-030-33850-3_2)    
â—¾ [VarGrad](https://arxiv.org/abs/1810.03307)    
â—¾ [SENN](https://arxiv.org/abs/1810.03307)    




### âœ… Tools & Applications
ğŸ”¸  [Heatmapping](http://www.heatmapping.org/)[web]    
ğŸ”¸  [CNN-explainer](https://poloclub.github.io/cnn-explainer/)[web]    
ğŸ”¸  [Explainable AI Demos](https://lrpserver.hhi.fraunhofer.de/)[web]    
ğŸ”¸  [A Neural Network Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=7,2,2,2&seed=0.40403&showTestData=false&discretize=false&percTrainData=50&x=true&y=false&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)[web]    
ğŸ”¸  [Summit](https://fredhohman.com/summit/)[web]    
ğŸ”¸  [NeuralDivergence](http://haekyu.com/neural-divergence/)[web]    
ğŸ”¸  [SCIN](https://www.dfki.de/skincare/classify.html)[web]    
ğŸ”¸  [Neuroscope](https://github.com/c3di/neuroscope)[software]   
ğŸ”¸  [LUCID](https://github.com/tensorflow/lucid)[library]    
ğŸ”¸  [Keras-vis](https://raghakot.github.io/keras-vis/)[library]    
ğŸ”¸  [DeepExplain](https://github.com/marcoancona/DeepExplain)[library]    
ğŸ”¸  [iNNvestigate](https://github.com/albermax/innvestigate)[library]  
ğŸ”¸  [TensorFlow Graph Visualizer](https://www.tensorflow.org/tensorboard/graphs)[library]    
ğŸ”¸  [tf-explain](https://tf-explain.readthedocs.io/en/latest/)[library]    
ğŸ”¸  [TorchRay](https://github.com/facebookresearch/TorchRay)[library]    
ğŸ”¸  [Captum](https://captum.ai/)[library]    
ğŸ”¸  [Explainable AI](https://cloud.google.com/explainable-ai)[commercial]    
ğŸ”¸  [Explainable AI Platform](https://datalanguage.com/scopa-scalable-explainable-ai)[commercial]    
ğŸ”¸  [exAID](https://exaid.kl.dfki.de/)[commercial]    
ğŸ”¸  [DASL](https://www.decodedhealth.com/)[commercial]

### âœ… Reviews

ğŸ”¹  [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/) A Guide for Making Black Box Models Explainable.
Christoph Molnar    
ğŸ”¹  [Towards Robust Interpretability with Self-Explaining Neural Networks](https://arxiv.org/abs/1806.07538), 2018    
ğŸ”¹  [Towards Explainable Artificial Intelligence](https://doi.org/10.1007/978-3-030-28954-6_1), 2019    
ğŸ”¹  [On the Integration of Knowledge Graphs into Deep Learning Models for a More Comprehensible AIâ€”Three Challenges for Future Research](https://doi.org/10.3390/info11020122), 2020    
ğŸ”¹  [Explainable Deep Learning: A Field Guide for the Uninitiated](https://arxiv.org/abs/2004.14545), 2020    
ğŸ”¹  [A Survey on Explainable Artificial Intelligence (XAI): Towards Medical XAI](https://arxiv.org/abs/1907.07374), 2020    
ğŸ”¹  [Explainable Artificial Intelligence (xAI) Approaches and Deep Meta-Learning Models](10.5772/intechopen.92172), 2020    
ğŸ”¹  [Explainable Deep Learning Models in Medical Image Analysis](https://doi.org/10.3390/jimaging6060052), 2020    
ğŸ”¹  [Achievements and Challenges in Explaining Deep Learning based Computer-Aided Diagnosis Systems](https://arxiv.org/abs/2011.13169), 2020    
ğŸ”¹  [Interpretability and Explainability: A Machine Learning Zoo Mini-tour](https://arxiv.org/abs/2012.01805), 2020    
ğŸ”¹  [Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications](10.1109/JPROC.2021.3060483), 2021    


### âœ… Evaluations
â—½ [The (Un)reliability of Saliency Methods: input variant](https://doi.org/10.1007/978-3-030-28954-6_14)    
â—½ [Sanity Checks for Saliency Maps: model and data](https://arxiv.org/abs/1810.03292)      
â—½ [Evaluating the Visualization of What a Deep Neural Network Has Learned: AOPC](https://ieeexplore.ieee.org/abstract/document/7552539)      



