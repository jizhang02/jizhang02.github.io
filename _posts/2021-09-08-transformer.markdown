---
layout:     post
title:      "Transformer's past and present."
subtitle: "Transformer的前世今生"
date:       2021-09-08 17:16:00
author:     "Jing"
header-img: "img/post-bg.jpg"
tags:
    - Computer Science
    - Deep Learning
    - Transformer
---

### Let you know the principle of AI models from excellent works
This post is an introduction to the Transformer, in terms of its origin, application and development.
![roadmap](/img/20210908_transformer.png)

## ![#60A917](https://via.placeholder.com/60/60A917/FFFFFF?text=2015) RNN 2015
⭐    
📄 [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
## ![#1BA1E2](https://via.placeholder.com/60/1BA1E2/FFFFFF?text=2016) RNN 2016    
⭐    
📄 [Long Short-Term Memory-Networks for Machine Reading](https://arxiv.org/abs/1601.06733)
## ![#6A00FF](https://via.placeholder.com/60/6A00FF/FFFFFF?text=2017) Transformer 2017
⭐    
📄 [Attention is all you need](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
## ![#FA6800](https://via.placeholder.com/60/FA6800/000000?text=2021) Transformer Vision 2021
⭐     
📄 [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
## ![#0050EF](https://via.placeholder.com/60/0050EF/FFFFFF?text=2021) Transformer Vision 2021
⭐    
📄    
👉 Acknowledgements: [Wang Shusen](https://youtu.be/aButdUV0dxI)
